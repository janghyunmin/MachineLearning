# import pandas as pd
# import numpy as np
# import matplotlib.pyplot as plt

# from sklearn.model_selection import train_test_split
# from sklearn.preprocessing import StandardScaler

# import tensorflow as tf
# from tensorflow.keras.layers import Dense
# from tensorflow import keras

# # ================================
# # 1. Load Data
# # ================================
# data_path = "./Data/Implied_Volatility_Data_vFinal.csv"
# raw = pd.read_csv(data_path)

# print("Data shape:", raw.shape)

# # ================================
# # 2. Feature engineering
# # ================================
# raw['x1'] = raw['SPX Return'] / np.sqrt(raw['Time to Maturity in Year'])
# raw['x2'] = raw['x1'] * raw['Delta']
# raw['x3'] = raw['x2'] * raw['Delta']

# X_imp = raw[['x1', 'x2', 'x3',
#              'SPX Return',
#              'Time to Maturity in Year',
#              'Delta']]

# y_imp = raw['Implied Volatility Change']

# # ================================
# # 3. Split Data
# # ================================
# X_train, X_test, y_train, y_test = train_test_split(
#     X_imp, y_imp, test_size=0.2, random_state=100
# )

# X_train, X_val, y_train, y_val = train_test_split(
#     X_train, y_train, test_size=0.25, random_state=100
# )

# # ================================
# # 4. Scaling (필수)
# # ================================
# scaler = StandardScaler()
# scaler.fit(X_train)

# Xs_train = scaler.transform(X_train)
# Xs_val = scaler.transform(X_val)
# Xs_test = scaler.transform(X_test)

# y_train = np.asarray(y_train)
# y_val = np.asarray(y_val)
# y_test = np.asarray(y_test)

# # ================================
# # 5. NN Model (Sigmoid 20-20-20)
# # ================================
# imvol_model = keras.models.Sequential([
#     Dense(20, activation="sigmoid", input_shape=(6,)),
#     Dense(20, activation="sigmoid"),
#     Dense(20, activation="sigmoid"),
#     Dense(1)
# ])

# imvol_model.summary()

# # ================================
# # 6. Compile (MSE)
# # ================================
# imvol_model.compile(loss="mse", optimizer="adam")

# # ================================
# # 7. Train (10,000 epochs)
# # ================================
# imvol_history = imvol_model.fit(
#     Xs_train,
#     y_train,
#     epochs=10000,
#     batch_size=128,     # 변경해도 OK
#     verbose=1,
#     validation_data=(Xs_val, y_val)
# )

# # ================================
# # 8. Plot Learning Curve (Custom Plot)
# # ================================
# plt.figure(figsize=(10,5))
# plt.plot(imvol_history.history['loss'], label='Training MSE')
# plt.plot(imvol_history.history['val_loss'], label='Validation MSE')
# plt.xlabel('Epochs')
# plt.ylabel('Mean Squared Error')
# plt.title('Training vs Validation MSE (Implied Volatility NN, 10,000 epochs)')
# plt.legend(['Training Set', 'Validation Set'])
# plt.grid(True)

# # 예제와 동일한 y축 범위 적용
# plt.gca().set_ylim(0.00004, 0.00015)
# plt.show()


import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

from tensorflow.keras.layers import Dense
from tensorflow import keras

# ======================================
# 1. Load Data
# ======================================
data_path = "./Data/Implied_Volatility_Data_vFinal.csv"
raw = pd.read_csv(data_path)

print(raw.shape)
raw.head()

# ======================================
# 2. Feature Engineering (예제 동일)
# ======================================
raw['x1'] = raw['SPX Return'] / np.sqrt(raw['Time to Maturity in Year'])
raw['x2'] = raw['x1'] * raw['Delta']
raw['x3'] = raw['x2'] * raw['Delta']

# 문제 조건: 총 6개 입력
X_imp = raw[['x1', 'x2', 'x3',
             'SPX Return',
             'Time to Maturity in Year',
             'Delta']]

y_imp = raw['Implied Volatility Change']

# ======================================
# 3. Train / Validation / Test Split
# ======================================
X_train, X_test, y_train, y_test = train_test_split(
    X_imp, y_imp, test_size=0.2, random_state=100
)

X_train, X_val, y_train, y_val = train_test_split(
    X_train, y_train, test_size=0.25, random_state=100
)

# ======================================
# 4. Scaling
# ======================================
scaler = StandardScaler()
scaler.fit(X_train)

Xs_train = scaler.transform(X_train)
Xs_val = scaler.transform(X_val)
Xs_test = scaler.transform(X_test)

y_train = np.asarray(y_train)
y_val = np.asarray(y_val)
y_test = np.asarray(y_test)

# ======================================
# 5. Neural Net Model (문제 조건: 3×20 Sigmoid)
# ======================================
imvol_model = keras.models.Sequential([
    Dense(20, activation="sigmoid", input_shape=(6,)),
    Dense(20, activation="sigmoid"),
    Dense(20, activation="sigmoid"),
    Dense(1)                         # output layer
])

imvol_model.summary()

# ======================================
# 6. Compile (Loss=MSE, Optimizer=Adam)
# ======================================
imvol_model.compile(loss="mse", optimizer="adam")

# ======================================
# 7. Train (Epochs=10,000)
# ======================================
imvol_history = imvol_model.fit(
    Xs_train,
    y_train,
    epochs=10000,
    batch_size=128,
    verbose=1,
    validation_data=(Xs_val, y_val)
)

# ======================================
# 8. Plot Result (예제 스타일)
# ======================================
plt.figure(figsize=(10,5))
plt.plot(imvol_history.history['loss'], label='Training Set')
plt.plot(imvol_history.history['val_loss'], label='Validation Set')
plt.grid(True)

# 예제와 동일한 Y축 범위 적용 (중요!)
plt.gca().set_ylim(0.00004, 0.00015)

plt.xlabel('Epochs')
plt.ylabel('Mean Squared Error')
plt.title('Implied Volatility NN: Training / Validation MSE vs Epoch\n(3×20 Sigmoid, Loss=MSE, Adam)')
plt.legend()
plt.show()
